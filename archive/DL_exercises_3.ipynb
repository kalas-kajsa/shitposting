{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_exercises_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoCJY7lLt5Gj"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.keras as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "import time # to log time. Get current time with time.time()\n",
        "from sklearn.model_selection import  train_test_split\n",
        "\n",
        "def legend_out(): # Helper function for putting legend outside the plot\n",
        "  plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "from tensorflow.keras.backend import clear_session\n",
        "\n",
        "# helper plotting function\n",
        "def plot_history_dt(history, dt=False):\n",
        "    loss = history.history['loss']  \n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = len(loss)\n",
        "    #times = history.history['times']\n",
        "    #times = [sum(times[:i]) for i in range(1,len(times)+1)]\n",
        "    if dt!=False:\n",
        "        times = [dt/len(loss)]*len(loss)\n",
        "        times = [sum(times[:i]) for i in range(1,len(times)+1)]\n",
        "        plt.plot(times, loss, label=\"train loss\")\n",
        "        plt.plot(times, val_loss, label=\"val loss\")\n",
        "    else:\n",
        "        plt.plot(loss, label=\"train loss\")\n",
        "        plt.plot(val_loss, label=\"val loss\")\n",
        "    legend_out()\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtkLwSI6qYYQ"
      },
      "source": [
        "## Testing Dropout and Batchnormalization.\n",
        "\n",
        "\n",
        "**Define** a model with the following structure:\n",
        "A Feedforward Network (Dense layers) with three hidden layers.\n",
        "\n",
        "Layer size = [100,100,100]+[output_size]\n",
        "\n",
        "Then:\n",
        "1. Define the same model but with Dropout applied to every layer but the last. Example with the functional model:\n",
        "\n",
        "\n",
        "```\n",
        "layer1 = nn.layers.Dense(100, activation=\"relu\")\n",
        "dropout = nn.layers.Dropout(0.2)(layer1) # dropout rate is 20%, i.e. 20% of the output of layer1 is set to 0.\n",
        "...\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "2. Define the same model but with BatchNormalization. Example:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "layer1 = nn.layers.Dense(100, activation=\"relu\")\n",
        "norm = nn.layers.BatchNormalization()(layer1) # we use all default parameters for the batch normalization.\n",
        "...\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "**Compile** the models with appropriate loss functions and desired metrics (e.g. accuracy). We will use the dataset called Fasion MNIST, which has 10 classes. If you use, for example, `sparse_categorical_crossentropy` as loss then you do not have to make your labels categorical before training (because of the \"sparse\" marker)! :)\n",
        "\n",
        "**Train** the models using the following setup:\n",
        "  - Log the time, using the `time` package in a variable `dt`(delta time). \n",
        "  - Use Adam optimizer with learning rate set to 0.002\n",
        "  - Use 20% of the training data as validation data with the validation_split argument.\n",
        "  - Add the following Callbacks that monitor validation loss:\n",
        "    - Early stopping `nn.callbacks.EarlyStopping(monitor=\"val_loss\", patience=?)`\n",
        "    - ReduceLROnPlataeu `nn.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=?)`\n",
        "    - For both callbacks, set `patience` appropriately considering the two questions: Should ReduceLearning rate have more or less patience? How long do you wait before stopping training?\n",
        "\n",
        "Plot the training and validation loss of the three models in relation to time of training. Hint: epochs can be tranformed to seconds trained if you use divide `dt` with number of epochs.\n",
        "\n",
        "Comment on which model is best in terms of speed and performance.\n",
        "\n",
        "Put this training procedure (the the best model) into a reusable function `def train_model(x_train,y_train, monitor_patience=[]))`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "JejYuDwBWJk3",
        "outputId": "e1a50da1-3fd2-45e4-b310-29d51a82a5bc"
      },
      "source": [
        "## Load data\n",
        "(x_train,y_train),(x_test,y_test) = nn.datasets.fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0],28*28) # flattening the images here :)\n",
        "x_train = x_train/255\n",
        "x_test = x_test.reshape(len(x_test),28*28)\n",
        "x_test = x_test/255\n",
        "fashion_des =pd.read_html('https://keras.io/api/datasets/fashion_mnist/')[0]\n",
        "fashion_des\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>T-shirt/top</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Trouser</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Pullover</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Dress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Coat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Sandal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Shirt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Sneaker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Bag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Ankle boot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label  Description\n",
              "0      0  T-shirt/top\n",
              "1      1      Trouser\n",
              "2      2     Pullover\n",
              "3      3        Dress\n",
              "4      4         Coat\n",
              "5      5       Sandal\n",
              "6      6        Shirt\n",
              "7      7      Sneaker\n",
              "8      8          Bag\n",
              "9      9   Ankle boot"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "VJUlt8eeWaYe",
        "outputId": "831bae3a-5092-4c79-ec6b-a9a65df2a283"
      },
      "source": [
        "# look at the data\n",
        "import random\n",
        "i = random.choice(range(len(x_train))) # take a random image\n",
        "fig,axes = plt.subplots(1,2)\n",
        "ax = axes[0]\n",
        "ax.imshow(x_train[i].reshape(28,28),cmap=plt.cm.gray) # reshaping the single image back to (28,28) to visualise it.\n",
        "ax = axes[1] \n",
        "ax.imshow(x_train[i].reshape(28,28),cmap=plt.cm.Spectral)\n",
        "fig.suptitle('%d: %s'%(y_train[i],fashion_des.Description.values[y_train[i]]));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9YgyJmOqXpb"
      },
      "source": [
        "# define and train the first model here (without dropout or batch normalization)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a8l1hAhvVJo"
      },
      "source": [
        "# define and train model with dropout here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKs0J3evvZZs"
      },
      "source": [
        "# define and train model with batch normalization here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saxs8Rg8yMS_"
      },
      "source": [
        "## Special layers for text data: Embeddings and RNNs\n",
        "In previous exercises we have only used the simple feedforward layer, connecting to every node in the previous layer. In the following we try out more specialized layers, layers especially for sequential and categorical data, in particular text data.\n",
        "\n",
        "# Embeddings\n",
        "Embedding is a simple mapping from a categorical item (e.g. a word), to a weight vector. Basically you allow the model to learn a unique set of weights for each word. \n",
        "If you think of the Dense feedforward layer as an input duplicator, just with different filters (i.e. unique weighing of each input parameter) one for each node defined in the layer. This means that the number of parameters/weights in a dense layer is n_units * n_inputs. \n",
        "Embeddings do not duplicate the input, but give each word an n-dimensional representation a set of weight it can use to encode information. This means that the shape of the resulting ouput is (number of words in the input, embedding_size). This means that it has two dimensions, instead of one from the simple feedforward layer computing a weighed sum for each node. \n",
        "A standard feedforward layer expects a one-dimensional input, so to feed a twodimensional input forward in the network one have to either flatten the matrix or pool (e.g. take the average or maximum value accross embedding dimensions) the input matrix (here you can use the Flatten or the AveragePool pr MaxPool layer). When average or maxpooling you throw out a lot of information (both the order and the individual variance). Flattening keeps the order but has many dimensions, so the model has to learn very precise ordered interactions, (i.e. a filter weighing dimensions from the 1 words and the 52 word. A more interesting idea is to use a specialized layer for processing sequences. The RNN goes through a list of weight vectors and produce an output for each, while keeping a hidden state that that each vector (word representation) can interact through - i.e. by changing the state, and being transformed by the current state. In theory this allows word_0 to interact with word_52 in the sequence, however in practice it is hard to learn such longterm dependencies. But lets try it out.\n",
        "\n",
        "\n",
        "### Train a Bidirectional LSTM Model.\n",
        "1. Define a network with the following 4 layers / blocks (as LSTM is more a block consisting of multiple layers): Embedding layer, Bidrectional LSTM, Dense, Dense output layer.\n",
        "\n",
        "The input_length to the embedding layer should equal 64 (the length of each sequence after running the `expand_data` funciton below), Embedding size should be 64, and LSTM should have 128 units, Dense should also have 128, and the final Dense layer should be chosen in relation to the number of classes in the prediction task. \n",
        "  - Embeddings take input the number of unique words, and the number of parameters for each word.\n",
        "  - Hint: You need to flatten the LSTM output before you feed it forward.\n",
        "2. Compile model. \n",
        "3. Train model.\n",
        "4. Evaluate model.\n",
        "5. Do the whole process but add dropout (both recurrent_dropout specific to the LSTM block ) and between the LSTM and the final layer. Evaluate model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RCezxrVJT8f",
        "outputId": "5a38aaeb-91b3-4da9-be57-f84283164405"
      },
      "source": [
        "\n",
        "### \n",
        "## Download data\n",
        "## Import IMDB data\n",
        "(x_train,y_train),(x_test,y_test) = nn.datasets.imdb.load_data()\n",
        "\n",
        "\"\"\" \n",
        "Data description:\n",
        "This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment \n",
        "(positive/negative). Reviews have been preprocessed, and each review is encoded \n",
        "as a list of word indexes (integers). For convenience, words are indexed by \n",
        "overall frequency in the dataset, so that for instance the integer \"3\" encodes \n",
        "the 3rd most frequent word in the data. This allows for quick filtering operations \n",
        "such as: \"only consider the top 10,000 most common words, but eliminate the top 20 \n",
        "most common words\".\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "## Function for making splitting documents into length 64.\n",
        "def expand_data(x,y,max_size=64):\n",
        "  new_x,new_y = [],[]\n",
        "  for xi,yi in zip(x,y):\n",
        "    for i in range(len(xi)//max_size):\n",
        "      temp = xi[i*max_size:(i+1)*max_size]\n",
        "      new_y.append(yi)\n",
        "      new_x.append(temp)\n",
        "  return np.array(new_x),np.array(new_y)\n",
        "\n",
        "\n",
        "x_train,y_train = expand_data(x_train,y_train)\n",
        "x_train,y_train = x_train,y_train\n",
        "x_test,y_test = expand_data(x_test,y_test)\n",
        "x_test,y_test = x_test,y_test\n",
        "print(len(x_train),len(x_test))\n",
        "w2id = nn.datasets.imdb.get_word_index()\n",
        "\n",
        "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.1)\n",
        "print(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "80859 77724\n",
            "[    7    15     8   140   187    12     9   444     6    55   737   829\n",
            "   585    10    10     4   105    26    53    40  5249   133    19    64\n",
            "    68  2857  6901     8  5390    23  1092  4826  3114  4021    42  2563\n",
            "   186     8    30    32    15 17870   134    84   261    12    70    30\n",
            " 11725    15    15  5981  3718    11 10225  2465     4   979     7     4\n",
            "    65     4  2467   863]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ISoBhVOVou2",
        "outputId": "e1b15854-b72b-41ca-93cc-cfeb3d13bb39"
      },
      "source": [
        "\"\"\" To view the original text, you can use this code to get the words from the indices\"\"\"\n",
        "\n",
        "# Reverse the word index to obtain a dict mapping indices to words\n",
        "inverted_word_index = dict((i, word) for (word, i) in w2id.items())\n",
        "\n",
        "# Decode the first sequence in the dataset\n",
        "decoded_sequence = \" \".join(inverted_word_index[i] for i in x_train[0])\n",
        "print(decoded_sequence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "br for in through however that it loved is time talk leads murder i i of films he up just ross scene film see were chilling flock in dose are d sincere suffered blowing it's performed horror in at an for expelled while great believe that well at attachment for for obtain drunken this scan highlight of christmas br of their of peace surprise\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh0gWLvKZchv",
        "outputId": "4faafed6-d7bb-4685-ca07-00c48cf0027c"
      },
      "source": [
        "# HELPER\n",
        "# As the vocab_size len(w2id) seems to be too small.\n",
        "# Instead use the maximum index of the input data, max(c)+1\n",
        "\n",
        "from collections import Counter\n",
        "c = Counter()\n",
        "for doc in list(x_train)+list(x_val)+list(x_test):\n",
        "  c.update(Counter(doc))\n",
        "len(c),len(w2id),max(w2id.values()),max(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84440, 88584, 88584, 88586)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uGMqD3FyLg1"
      },
      "source": [
        "# Solution goes here.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVVtCVWo_goK"
      },
      "source": [
        "## Transfer learning using pretrained embeddings\n",
        "In data setups with very few labeled examples transfer learning can be useful, also in the context of this rather simple model. Instead of learning the word embeddings from the task, we shall use pretrained embeddings. This exercise is designed for you to interact a little more with the model obejct, while simple transfer learning on text data. This means interacting with the weights to manually change them, and also adjusting which layers have trainable parameters in a simple transfer learning scheme. We will download the \"Glove\" embeddings from Gensim and match the Word embedding index from glove to the wordindex from Keras (`w2id`).\n",
        "\n",
        "1. Build the same model as before (but with a larger embedding to match with pretrained Glove embeddings).\n",
        "2. Build the embedding matrix with weights from Glove.\n",
        "  - Hint: first define a matrix with random values between 0 and 1, and with shape `(vocab_size,emb_size)`, where vocab_size=max(c)+1. Then iterate through the w2id index and set the row of the embedding matrix with the glove representation:  `emb_model.get_vector(word)`. Use try-except to only update the matrix if the word in w2id also exists in `emb_model.get_vector(word)`.\n",
        "\n",
        "The key to transfer learning is to avoid what is known as Catastrophic Forgetting, where the pretrained parts of the model are just forgotten during training. This is particularly a problem in the beginnig of training where gradients are large, as the model has yet to learn anything. Also a transfer learning model is often much to large relative to the amount of traning data -  no. parameters to no. labels examples. As we know this will lead to overfitting. To avoid this we limit the number of *trainable* parameters by \"freezing\" certain layers. That is the model can still be very large, but the parameters that learn are small. Once gradients have stabilized (due to much lower loss), one can finetune the pretrained parts also. \n",
        "### Transfor Learning Scheme: Freezing and Unfreezing\n",
        "3. Freeze the embedding layer, by setting the `.trainable` attribute of that layer (`model.layers`) to `False`. (Hint: \"Setting\" just means a standard python assignment using the `=` sign.)\n",
        "4. Train model for 3 epochs. \n",
        "5. Plot history and evaluate.\n",
        "6. Unfreeze embedding layer and finetune for one epoch.\n",
        "7. Evaluate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whvkEOWSEMzJ",
        "outputId": "51926395-c9aa-4ca3-d65e-6ab231ca6d0b"
      },
      "source": [
        "## Download embeddings.\n",
        "import gensim.downloader as api\n",
        "info = api.info()  # return dict with info about available models/datasets\n",
        "print(info['models']['glove-wiki-gigaword-300'])\n",
        "emb_model = api.load('glove-wiki-gigaword-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'num_records': 400000, 'file_size': 394362229, 'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-300/__init__.py', 'license': 'http://opendatacommons.org/licenses/pddl/', 'parameters': {'dimension': 300}, 'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).', 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-300.txt`.', 'read_more': ['https://nlp.stanford.edu/projects/glove/', 'https://nlp.stanford.edu/pubs/glove.pdf'], 'checksum': '29e9329ac2241937d55b852e8284e89b', 'file_name': 'glove-wiki-gigaword-300.gz', 'parts': 1}\n",
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEEoBNkskxXP"
      },
      "source": [
        "#your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}